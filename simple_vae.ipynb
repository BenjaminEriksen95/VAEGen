{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple VAE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "The following code contains the required libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "#import torchbearer\n",
    "#import torchbearer.callbacks as callbacks\n",
    "#from torchbearer import Trial, state_key\n",
    "#MU = state_key('mu')\n",
    "#LOGVAR = state_key('logvar')\n",
    "\n",
    "#import ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Settings\n",
    "#classes = [0, 1, 4, 9]\n",
    "batch_size = 64\n",
    "eval_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Import\n",
    "#source 7.1 autoencoder lab\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# transforms into tensor, can be extend\n",
    "transformations = transforms.Compose([transforms.ToTensor()]) \n",
    "\n",
    "\n",
    "# Define the train and test sets\n",
    "train_data = MNIST(\"./\", train=True,  transform=transformations, download=True)\n",
    "test_data  = MNIST(\"./\", train=False, transform=transformations)\n",
    "\n",
    "\n",
    "#def stratified_sampler(labels):\n",
    "#    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "#    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "#    indices = torch.from_numpy(indices)\n",
    "#    return SubsetRandomSampler(indices)\n",
    "\n",
    "#load the datasets into DataLoader classes, sampler removed!\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_data, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model \n",
    "\n",
    "inspired by: https://www.kaggle.com/ethanwharris/fashion-mnist-vae-with-pytorch-and-torchbearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://debuggercafe.com/getting-started-with-variational-autoencoder-using-pytorch/\n",
    "def final_loss(bce_loss, mu, logvar):\n",
    "    BCE = bce_loss\n",
    "    KLD = -.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "latent_size = 5\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (mu): Linear(in_features=3136, out_features=5, bias=True)\n",
      "  (logvar): Linear(in_features=3136, out_features=5, bias=True)\n",
      "  (upsample): Linear(in_features=5, out_features=3136, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv1 = (1, 32, 4, 1, 2)\n",
    "conv2 = (conv1[1], 32, 4, 2, 1)\n",
    "conv3 = (conv2[1], 64, 4, 2, 1)\n",
    "\n",
    "\n",
    "##Look at 7.2 to see how to make encoder and decoder take non-fixed size image. \n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(VariationalAutoEncoder,self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=conv1[0],out_channels=conv1[1],kernel_size=conv1[2],stride=conv1[3],padding=conv1[4]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=conv2[0],out_channels=conv2[1],kernel_size=conv2[2],stride=conv2[3],padding=conv2[4]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=conv3[0],out_channels=conv3[1],kernel_size=conv3[2],stride=conv3[3],padding=conv3[4]),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=conv3[1],out_channels=conv3[0],kernel_size=conv3[2],stride=conv3[3],padding=conv3[4]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=conv2[1],out_channels=conv2[0],kernel_size=conv2[2],stride=conv2[3],padding=conv2[4],output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=conv1[1],out_channels=conv1[0],kernel_size=conv1[2],stride=conv1[3],padding=conv1[4]),\n",
    "            )\n",
    "        \n",
    "        self.mu = nn.Linear(64 * 7 * 7, latent_size)\n",
    "        self.logvar = nn.Linear(64 * 7 * 7, latent_size)\n",
    "        self.upsample = nn.Linear(latent_size, 64 * 7 * 7)\n",
    "        \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "        \n",
    "    # https://debuggercafe.com/getting-started-with-variational-autoencoder-using-pytorch/    \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1,64*7*7)\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.logvar(x)\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        # decoding\n",
    "        z = self.upsample(z)\n",
    "        #print(z.shape)\n",
    "        z = z.view(-1,64,7,7)\n",
    "        \n",
    "        x = self.decoder(z)\n",
    "        reconstruction = torch.sigmoid(x)\n",
    "        \n",
    "        return reconstruction, mu, log_var\n",
    "        \n",
    "     \n",
    "print(VariationalAutoEncoder(latent_size=latent_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def beta_kl(mu_key, logvar_key, beta=5):\n",
    "#    #@callbacks.add_to_loss\n",
    "#    def callback(state):\n",
    "#        mu = state[mu_key]\n",
    "#        logvar = state[logvar_key]\n",
    "#        return -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * beta\n",
    "#    \n",
    "#    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_progress(key=torchbearer.Y_PRED, num_images=100, nrow=10):\n",
    "#    #@callbacks.on_step_validation\n",
    "#    #@callbacks.once_per_epoch\n",
    "#    def callback(state):\n",
    "#        images = state[key]\n",
    "#        image = make_grid(images[:num_images], nrow=nrow, normalize=True)[0, :, :]\n",
    "#        plt.imshow(image.detach().cpu().numpy(), cmap=\"gray\")\n",
    "#        plt.show()\n",
    "#    \n",
    "#    return callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(latent_size=latent_size)\n",
    "optimizer = optim.Adam(vae.parameters(),lr=learning_rate)\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_vae(vae, train_loader):\n",
    "    vae.train()\n",
    "    running_loss = 0.0\n",
    "    # Run each batch in training dataset\n",
    "    for x, y in train_loader:\n",
    "        # x.view?\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction, mu, logvar = vae(x)\n",
    "        bce_loss = criterion(reconstruction, x)\n",
    "        loss = final_loss(bce_loss, mu, logvar)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "def test_vae(vae, test_loader):\n",
    "    vae.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            # x.view?\n",
    "            x = x.to(device)\n",
    "            reconstruction, mu, logvar = vae(x)\n",
    "            bce_loss = criterion(reconstruction, x)\n",
    "            loss = final_loss(bce_loss, mu, logvar)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    val_loss = running_loss/len(test_loader.dataset)\n",
    "    return val_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cuda:0\n",
      "Epoch 1 of 20\n",
      "Train Loss: 124.2903\n",
      "Val Loss: 126.9559\n",
      "Epoch 2 of 20\n",
      "Train Loss: 123.5877\n",
      "Val Loss: 126.7237\n",
      "Epoch 3 of 20\n",
      "Train Loss: 123.0580\n",
      "Val Loss: 125.1069\n",
      "Epoch 4 of 20\n",
      "Train Loss: 122.6120\n",
      "Val Loss: 125.2017\n",
      "Epoch 5 of 20\n",
      "Train Loss: 122.2345\n",
      "Val Loss: 124.3963\n",
      "Epoch 6 of 20\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "vae = vae.to(device)\n",
    "\n",
    "##\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for current_epoch in range(num_epochs):\n",
    "    print(f\"Epoch {current_epoch+1} of {num_epochs}\")\n",
    "    train_epoch_loss = fit_vae(vae, train_loader)\n",
    "    test_epoch_loss = test_vae(vae, test_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    test_loss.append(test_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Val Loss: {test_epoch_loss:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (with torchbearer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-19b2718c36f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariationalAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trial = Trial(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trial' is not defined"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoEncoder(latent_size=latent_size)\n",
    "optimizer = optim.Adam(vae.parameters(),lr=learning_rate)\n",
    "trial = Trial(\n",
    "    vae, \n",
    "    optimizer, \n",
    "    nn.MSELoss(reduction='mean'), metrics=['acc', 'loss'], \n",
    "    callbacks=[\n",
    "        beta_kl(MU, LOGVAR),\n",
    "        callbacks.ConsolePrinter(),\n",
    "        plot_progress()],\n",
    "    verbose=1).with_generators(train_generator=train_loader,test_generator=test_loader)\n",
    "trial.to('cuda')\n",
    "trial.run(5)\n",
    "trial.evaluate(verbose=0, data_key=torchbearer.TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2f67b8e3630c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariationalAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m trial = Trial(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trial' is not defined"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoEncoder(latent_size=latent_size)\n",
    "optimizer = optim.Adam(vae.parameters(),lr=learning_rate)\n",
    "trial = Trial(\n",
    "    vae, \n",
    "    optimizer, \n",
    "    #mean-squared error or cross-entropy\n",
    "    nn.MSELoss(reduction='sum'), metrics=['acc', 'loss'], \n",
    "    callbacks=[\n",
    "        beta_kl(MU, LOGVAR),\n",
    "        callbacks.ConsolePrinter(),\n",
    "        plot_progress()],\n",
    "    verbose=1).with_generators(train_generator=train_loader,test_generator=test_loader)\n",
    "trial.to('cuda')\n",
    "trial.run(5)\n",
    "trial.evaluate(verbose=0, data_key=torchbearer.TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
