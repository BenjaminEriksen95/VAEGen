{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=32\n",
    "# train = MNIST(\n",
    "#     root='data', train=True, transform=transforms.ToTensor(),\n",
    "#     download=True)\n",
    "# test= MNIST(\n",
    "#     root='data', train=True, transform=transforms.ToTensor(),\n",
    "#     download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bs=32*8*2\n",
    "train = FashionMNIST(\n",
    "    root='data', train=True, transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "test= FashionMNIST(\n",
    "    root='data', train=True, transform=transforms.ToTensor(),\n",
    "    download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sampler(labels,classes):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2,3,4,5]\n",
    "num_classes=len([0,1,2])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train,\n",
    "  batch_size=bs,sampler=stratified_sampler(train.targets,classes))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test,\n",
    "  batch_size=bs,sampler=stratified_sampler(test.targets,classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#     plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(torch.nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNprint_=False\n",
    "class NNprint(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        if NNprint_==True:\n",
    "            print(input.shape)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, image_channels=1, h_dim=1024, z_dim=32,num_labels=0):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            NNprint(),\n",
    "            torch.nn.Conv2d(image_channels, 32, kernel_size=3, stride=2),\n",
    "            NNprint(),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=2),\n",
    "            NNprint(),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
    "            NNprint(),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1),\n",
    "            NNprint(),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            Flatten(),\n",
    "            \n",
    "            \n",
    "            NNprint(),\n",
    "            \n",
    "        )\n",
    "        self.h_dim=h_dim\n",
    "        self.num_labels=num_labels\n",
    "        self.fc1 = torch.nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = torch.nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = torch.nn.Linear(z_dim+num_labels, h_dim)\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            NNprint(),\n",
    "            UnFlatten(),\n",
    "            NNprint(),\n",
    "            torch.nn.ConvTranspose2d(h_dim, 128, kernel_size=4, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            NNprint(),\n",
    "            torch.nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            NNprint(),\n",
    "            torch.nn.ConvTranspose2d(64, 32, kernel_size=4,padding=0, stride=2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            NNprint(),\n",
    "            torch.nn.ConvTranspose2d(32, image_channels, kernel_size=5, stride=1),\n",
    "            torch.nn.Sigmoid(),\n",
    "            NNprint(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu.to(device) + std.to(device) * esp.to(device)\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h,labels):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        if self.num_labels>0:\n",
    "            z=torch.cat((z,torch.nn.functional.one_hot(labels,self.num_labels).type(torch.float).to(device)),1)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x,labels):\n",
    "        h = self.encoder(x)\n",
    "#         h=torch.cat((h,labels.float().reshape(labels.size(0),1).to(device)),dim=1)\n",
    "        z, mu, logvar = self.bottleneck(h,labels)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x,labels):\n",
    "        z, mu, logvar = self.encode(x,labels)\n",
    "#         print('z',z.shape)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def sample(self,z):\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_channels = example_data.size(1)\n",
    "image_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(image_channels=image_channels,h_dim=1024,z_dim=8).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.to(device), size_average=False,reduction='sum' )\n",
    "    # BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] Loss: 219.670 219.653 0.017\n",
      "Epoch[2/100] Loss: 218.698 218.683 0.015\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(epochs):\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "#         print(idx)\n",
    "        recon_images, mu, logvar = model(images.to(device),labels)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx%500==0:\n",
    "            to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                        epochs, loss.data.cpu().numpy().tolist()/bs, bce.data.cpu().numpy().tolist()/bs, kld.data.cpu().numpy().tolist()/bs)\n",
    "            print(to_print)\n",
    "torch.save(model.state_dict(), 'vae.torch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#     plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_nn=model(example_data.to(device),example_targets)\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data_nn[0][i][0].cpu().data, cmap='gray', interpolation='none')\n",
    "#     plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(model=None,sample=False,data=None):\n",
    "    if data is None:\n",
    "        if (model==None):\n",
    "            batch_idx, (data, example_targets) = next(examples)\n",
    "        else:\n",
    "            batch_idx, (data, example_targets) = next(examples)\n",
    "            if sample:\n",
    "                zeros=torch.zeros(10,1024)\n",
    "                samples= torch.cat((torch.rand(32,1024),zeros)).T\n",
    "                data = model.sample(samples.to(device))\n",
    "            else:\n",
    "                data = model(data.to(device),example_targets)[0]\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(15)\n",
    "    fig.set_figwidth(15)\n",
    "    for i in range(64):\n",
    "        plt.subplot(8,8,i+1)\n",
    "        plt.tight_layout()\n",
    "        if model:\n",
    "            plt.imshow(data[i][0].cpu().data, cmap='gray', interpolation='none')\n",
    "        else:\n",
    "            plt.imshow(data[i][0], cmap='gray', interpolation='none')\n",
    "    #     plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=torch.zeros(10,64)\n",
    "c=0\n",
    "for i in zeros:\n",
    "    \n",
    "    zeros[c,c]+=1\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        c=0\n",
    "        \n",
    "    \n",
    "range_=np.linspace(0,1,8)\n",
    "samples=(torch.ones(8,64)*0.5).T\n",
    "for c in range(64):\n",
    "    samples[c][int(c/8)]=range_[c%8]\n",
    "smple_pic =model.sample(samples.to(device))\n",
    "plot_examples(model=True,data=smple_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=torch.zeros(10,64)\n",
    "c=0\n",
    "for i in zeros:\n",
    "    \n",
    "    zeros[c,c]+=1\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        c=0\n",
    "        \n",
    "    \n",
    "range_=np.linspace(0,1,8)\n",
    "samples=(torch.ones(8,64)*0.1).T\n",
    "for c in range(64):\n",
    "    samples[c][int(c/8)]=range_[c%8]\n",
    "smple_pic =model.sample(samples.to(device))\n",
    "plot_examples(model=True,data=smple_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=torch.zeros(10,64)\n",
    "c=0\n",
    "for i in zeros:\n",
    "    \n",
    "    zeros[c,c]+=1\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        c=0\n",
    "        \n",
    "    \n",
    "range_=np.linspace(0,1,8)\n",
    "samples=(torch.ones(8,64)*0.6).T\n",
    "for c in range(64):\n",
    "    samples[c][int(c/8)]=range_[c%8]\n",
    "smple_pic =model.sample(samples.to(device))\n",
    "plot_examples(model=True,data=smple_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
